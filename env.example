# Cloud LLM Inference Benchmark - Environment Variables
# Copy this file to .env and fill in your values
# Command: cp env.example .env

# HuggingFace Token (required for accessing LLaMA models)
# Get your token from: https://huggingface.co/settings/tokens
HUGGINGFACE_TOKEN=your_huggingface_token_here

# Model Configuration
# Options: facebook/opt-125m (small), meta-llama/Llama-3.2-1B, etc.
MODEL_NAME=facebook/opt-125m

# Server URLs (for local testing)
VLLM_URL=http://localhost:8000
SGLANG_URL=http://localhost:30000

# AWS Configuration (for deployment script)
AWS_REGION=us-east-1
AWS_INSTANCE_TYPE=g5.xlarge
AWS_KEY_NAME=your-key-pair
AWS_KEY_PATH=~/.ssh/your-key.pem



